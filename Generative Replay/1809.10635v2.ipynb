{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "cm.update(\n",
    "    \"rise\",\n",
    "    {\n",
    "        \"theme\": None,\n",
    "        \"transition\": None,\n",
    "        \"start_slideshow_at\": \"selected\",\n",
    "        \"leap_motion\": {\n",
    "            \"naturalSwipe\"  : True,     # Invert swipe gestures\n",
    "            \"pointerOpacity\": 0.5,      # Set pointer opacity to 0.5\n",
    "            \"pointerColor\"  : \"#d80000\" # Red pointer\"nat.png\"\n",
    "        },\n",
    "        \"header\": \"<h3>Francisco Perez-Sorrosal</h3>\",\n",
    "        \"footer\": \"<h3>Machine Learning/Deep Learning</h3>\",\n",
    "        \"scroll\": True,\n",
    "        \"enable_chalkboard\": True\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "print(emoji.emojize('Presenting stuff is easy!!! :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Emojis http://getemoji.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brain-inspired replay for continual learning with artiÔ¨Åcial neural networks\n",
    "[Nature (13 August 2020)](https://www.nature.com/articles/s41467-020-17866-2)\n",
    "## Gido M. van de Ven & Hava T. Siegelmann & Andreas S. Tolias\n",
    "\n",
    "\n",
    "## With Excerps from:\n",
    "\n",
    "### \"Three Scenarios for Continual Learning\" [https://arxiv.org/pdf/1904.07734.pdf](https://arxiv.org/pdf/1904.07734.pdf)\n",
    "#### Gido M. van de Ven & Andreas S. Tolias\n",
    "### \"Generative Replay with Feedback Connections as a General Strategy for Continual Learning\"  [https://arxiv.org/pdf/1809.10635v2.pdf](https://arxiv.org/pdf/1809.10635v2.pdf)\n",
    "#### Gido M. van de Ven & Andreas S. Tolias\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Francisco Perez-Sorrosal | 14 Nov 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relationships Among the Papers\n",
    "\n",
    "1. Generative Replay with Feedback Connections as a General Strategy for Continual Learning\n",
    "2. Three Scenarios for Continual Learning\n",
    "3. Brain-inspired replay for continual learning with artiÔ¨Åcial neural networks\n",
    "\n",
    "\n",
    "### Relationships:\n",
    "\n",
    "* 1 : Aims at describing a new *scalable generative replay* method to avoid catastrophic forgetting in lifelong learning\n",
    "* 1 -> 2 : As part of it, the authors suggest a new framework for **fair evaluation of catastrophic forgetting** consisting in 3 different scenarios for Incremental Learning\n",
    "* 1 + 2 + extensions -> 3  : Extends the *scalable generative replay* from 1. with additional SotA brain-research techniques in neuroscience and applied to the scenarios described in 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Context:\n",
    "\n",
    "- Catastrophic Forgetting: Cites McCloskey and Ratcliff psychology-based papers from early 90's on the problems of the connectionist paradigm for avoiding \"memory loss\"\n",
    "\n",
    "    \"New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.\"\n",
    "\n",
    "    -- McCloskey et al.\n",
    "\n",
    "## Main contributions:\n",
    "All along the three papers, the main contributions are:\n",
    "\n",
    "üí° Make comparison of continual learning scenarios easier and more rigurous\n",
    "  - Identifies 3 distinct scenarios depending on if the task identity is provided at test time or not.\n",
    "\n",
    "üí° Compare recently proposed methods on continual learning\n",
    "\n",
    "üí° Propose a new fast, scalable and competitive (performance-wise) generative replay approach that behaves well in the 3 scenarios proposed\n",
    "\n",
    "üí° Extend the new generative replay approach proposed with recent techniques extracted from neuroscience applied to the structure of the ANN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Continual Learning Scenarios\n",
    "\n",
    "üí° **KEY**: *WHETHER OR NOT* the model is required to identify the identity of the task it has to solve at test time\n",
    "\n",
    "  - e.g. In N. Masse et al.'s \"Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization\", which assumes task identity is always available, it is reported a great improvement over SotA.\n",
    "\n",
    "\n",
    "##  Scenarios:\n",
    " \n",
    " 1. Models are **always** informed about which task is solving (Task-IL)\n",
    " \n",
    " \n",
    " 2. Models **do not know** the task identity at test time (domain-incremental learning, Domain-IL)\n",
    "   - However, the model do not need to infer the task, only solve it\n",
    " \n",
    " \n",
    " 3. Models need to both, **solve each task seen and infer which task** are currently evaluating (class-incremental learning, Class-IL)\n",
    " \n",
    " ![3Scenarios for CL](images/3scenarios.png)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Three Scenarios for Continual Learning (pdf)](https://arxiv.org/pdf/1904.07734.pdf)\n",
    "\n",
    "## Gido M. van de Ven & Andreas S. Tolias\n",
    "\n",
    "### Neurips 2019\n",
    "\n",
    "\n",
    "Extended description of the scenarios addressing the following:\n",
    "\n",
    "üí° The scenarios for Continual Learning Analisys\n",
    "\n",
    "üí° Strategies for Continual Learning\n",
    "\n",
    "üí° Experiments based on the previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Scenarios\n",
    "\n",
    "## Task-IL\n",
    "\n",
    "- The easiest continual learning scenario\n",
    "- Models are always informed about which task needs to be performed\n",
    "- It's possible to train models with task-specific components. \n",
    "- Typical network architecture in this scenario has a ‚Äúmulti-headed‚Äù output layer\n",
    "\n",
    "## Domain-IL\n",
    "\n",
    "- Task identity is not available at test time\n",
    "- BUT... models however only need to **solve the task**, not infer the current task\n",
    "- Task structure is always the same, **BUT** the input-distribution changes\n",
    "- Example: agents that have to survive in different envs without previous knowledge of the environment itself\n",
    "\n",
    "## Class-IL\n",
    "\n",
    "- Models have to solve each task seen AND infer the new current task\n",
    "- Name refers to the fact that the model has to learn to identify new classes of objects like infants do in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Single Headed vs Multi-Headed Methods\n",
    "\n",
    "Classical view of the continual learning:\n",
    "\n",
    "üí° A multi-headed layout requires task identity to be known (Task-IL)\n",
    "\n",
    "üí° A single-headed layout **DOES NOT** requires the task identity to be known (Domain-IL/Class-IL)\n",
    "\n",
    "This distinction is done **based on the architectural layout of a network‚Äôs output layer**. \n",
    "\n",
    "- **BUT** despite using a separate output layer for each task, it is the most common way to have specific task identity information, **it is not the only way**\n",
    "\n",
    "- For a single-headed layout might by\n",
    "itself not require task identity to be known, it is still possible for the model to use task identity in\n",
    "other way (See \"Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization\" by N. Masse et al.)\n",
    "\n",
    "## Major differences/advantages of the 3 scenarios proposal vs the Single/Multi Headed classical view...\n",
    "\n",
    "1. The scenarios proposed in the paper reflect more generally the conditions under which a model is evaluated.\n",
    "\n",
    "2. The scenarios extend upon the multi-headed vs single-headed split by recognizing that:\n",
    "    - when task identity is not provided, there is a further distinction depending on whether the network is explicitly required to infer task identity\n",
    "    - the two scenarios resulting from this additional split substantially differ in difficult\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example Task Protocols\n",
    "\n",
    "üí° Goal is twofold: \n",
    "\n",
    "1. Show that any task protocol can be performed according to each scenario\n",
    "  -  Exercised through two different task protocols for all three scenarios\n",
    "2. Demonstrate the difference between the three continual learning scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Protocols\n",
    "\n",
    "### Sequentially learning to classify MNIST-digits\n",
    "\n",
    "\n",
    "![Split MNIST](images/splitmnist.png)\n",
    "\n",
    "\n",
    "\n",
    "* Demonstrates:\n",
    "\n",
    "\n",
    "\n",
    "1. The Task-IL scenario\n",
    "  - It is sometimes referred to as ‚Äòmulti-headed split MNIST‚Äô\n",
    "  \n",
    "2. The Class-IL scenario\n",
    "  - It is referred to as ‚Äòsingle-headed split MNIST‚Äô\n",
    "  \n",
    "3. It could also be performed under the Domain-IL scenario\n",
    "\n",
    "\n",
    "![Split MNIST](images/splitmnistscenarios.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Permuted MNIST\n",
    "\n",
    "- Each task involves classifying all ten MNIST-digits but with a different permutation applied to the pixels for every new task (Figure 2). \n",
    "\n",
    "![Permuted MNIST](images/permutedmnist.png)\n",
    "\n",
    "\n",
    "* Demonstrates:\n",
    "\n",
    "\n",
    "1. Naturally the Domain-IL scenario\n",
    "2. But also it can be performed according to the other scenarios too.\n",
    "\n",
    "![Permuted MNIST](images/permutedmnistscenarios.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Task Boundaries\n",
    "\n",
    "\n",
    "## Important Assumption: \n",
    "\n",
    "**In training, there are clear and well-defined boundaries between the tasks to be learned**\n",
    "\n",
    "* **Objective of well defined boundaries?**\n",
    "  - Make the continual learning process more structured\n",
    "  - Without that structure, the scenarios described become blurry\n",
    "\n",
    "## Implications:\n",
    "\n",
    "* Among others, **training with randomly-sampled minibatches** and **multiple passes over each task‚Äôs training data** are no longer possible. \n",
    "* Without well-defined task-boundaries, see **Task agnostic continual learning using online variational bayes** by *C. Zeno et al.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods Compared\n",
    "\n",
    "## [XdG](https://www.pnas.org/content/115/44/E10467)\n",
    "\n",
    "- Inherited from the Context-dependent gating concept from neurosciences\n",
    "- Task switching disinhibits nonoverlapping sets of sparse dendritic branches\n",
    "    - Intersection of changes ~ 0; Minimal interference of synaptic changes for one task with synaptic changes that occurred for previous tasks\n",
    "- Simplified version of this XdG\n",
    "    - Algorithm sends an additional signal unique for each task, which is projected onto all hidden neurons\n",
    "    - X% of the units in each hidden layer was fully gated (i.e., their activations set to zero)\n",
    "        - X treated as a hyperparameter (set by grid search)\n",
    "    - In summary: **Each node in the ANN (randomly and a priori) is assigned to be involved in each task**\n",
    "- Small computational impact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods Compared: Regularization-based\n",
    "\n",
    "- Add a regularization term to the loss\n",
    "- The impact of regularization is controlled by a hyperparameter $Œª$\n",
    "- $L_{total} = L_{current} + Œª * L_{regularization}$\n",
    "\n",
    "## [EWC, Elastic Weight Consolidation](https://arxiv.org/abs/1612.00796)\n",
    "\n",
    "- Main difference with XdG:\n",
    "    - Train a different part of the network for each task, but always use the entire network for execution\n",
    "- HOW? \n",
    "    - Regularize the ANN params while training each new task\n",
    "    - For all params in the ANN it is estimated they are for the previously learned tasks\n",
    "        - Depending on this, they are penalized for future changes\n",
    "        - This is equivalent to reduce the learning process in some parts of the network that are supposedly \"remembering\" the previous tasks\n",
    "- Suitable for reinforcement learning scenarios\n",
    "- Favours more the initial tasks\n",
    "\n",
    "## [online EWC](https://arxiv.org/pdf/1805.06370.pdf)\n",
    "\n",
    "- **EWC criticism** from [this paper](https://arxiv.org/abs/1712.03847): \n",
    "    -  For two tasks, EWC is ~ a diagonalized Laplace approximation, with a new hyperparameter $Œª_A$ that tries to signify the task importance\n",
    "    - Basically the critizism states of EWC that, when more than two tasks are considered, the quadratic penalties in EWC are inconsistent with this derivation (grows linearly with the number of tasks) and might lead to double-counting data from earlier tasks.\n",
    "\n",
    "- Online EWC is a modification of EWC focused on scalability\n",
    "- Favours more the most recent past\n",
    "- Tries to tame growth of the computational cost of the regularization\n",
    "\n",
    "\n",
    "## [SI, Synaptic Intelligence](https://arxiv.org/abs/1703.04200)\n",
    "\n",
    "- **NOT DIRECTLY related to biological mechanisms, just observations:** \"While we make no claim that biological synapses behave like the intelligent synapses of our model, a wealth of experimental data in neurobiology suggests that biological synapses act in much more complex ways than the artificial scalar synapses that dominate current machine learning models. *In essence, whether synaptic changes occur, and whether they are made permanent, or left to ultimately decay, can be controlled by many different biological factors.*\"\n",
    "\n",
    "- Similar to EWC in the sense of training part of the ANN per task, but fully use the ANN for execution\n",
    "    - Paper states: \"The regularization penalty is similar to EWC as recently introduced by Kirkpatrick et al. (2017).\"\n",
    "- On the contrary to EWC, SI computes the per-synapse consolidation strength:\n",
    "    - Online (Similar to what is proposed in online EWC)\n",
    "    - Over the entire learning trajectory in parameter space\n",
    "- Conjeturates that individual synapses not correspond simply to single scalar synaptic weights, and imnplements them to behave as a higher dimensional dynamical systems\n",
    "- These high dimensional states of these SI synapses makes possible:\n",
    "    - Accumulate task relevant information in a more efficient way during training\n",
    "    - Retain a memory of previous parameter values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods Compared: Replay-based methods\n",
    "\n",
    "- Add a loss-term for the replayed data. \n",
    "- A hyperparameter could be avoided\n",
    "    - The loss for current/replayed data can be weighted according to the # of tasks the model has been trained on so far\n",
    "    - $L_{total} = 1/N_{tasks so far} * L_{current} + (1 - 1/N_{tasks so far}) * L_{replay}$\n",
    "    \n",
    "\n",
    "## [LwF, Learning Without Forgetting](https://arxiv.org/abs/1606.09282)\n",
    "\n",
    "- Considered by the authors a replay-based method\n",
    "- Train a model M1 for task, A with labeled data -> Label input data for task B with M1 -> Use the resulting input-target pairs as pseudo-data for task B.\n",
    "- Inputs to be replayed labeled with ‚Äúhard targets‚Äù + ‚Äúsoft targets‚Äù\n",
    "    - ‚Äúhard targets‚Äù - the most likely category according to the previous tasks‚Äô model\n",
    "    - ‚Äúsoft targets‚Äù - previous tasks‚Äô model predicted probabilities for all target classes\n",
    "- Goal for the replayed data: to match the probabilities predicted by the model being trained to these target probabilities. Similar to distillation.\n",
    "\n",
    "![LWF1](images/lwf1.png)![LWF2](images/lwf2.png)![LWF3](images/lwf3.png)\n",
    "\n",
    "\n",
    "## [DGR](http://arxiv.org/abs/1705.08690)\n",
    "- Two models:\n",
    "    - **Generative model** -- creates data to be replayed, sequentially trained on all tasks (according to each task's input data distribution)\n",
    "    - **Main model** -- used for evaluate task performance (classification, etc.)\n",
    "- Input samples were paired with ‚Äúhard targets‚Äù provided by the main model\n",
    "\n",
    "\n",
    "## [DGR+distill](https://arxiv.org/abs/1802.00853)\n",
    "\n",
    "- Combination of LwF and DGR\n",
    "- Separate generative model trained to generate images to be replayed, but these were then paired with soft targets (LwF) instead of hard targets (DGR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bonus: Continual Learning Methods Classification\n",
    "\n",
    "Source: [A continual learning survey: Defying forgetting in classification tasks (2020)](https://arxiv.org/pdf/1909.08383.pdf)\n",
    "\n",
    "![continual_learning_methods](images/contlearningmethods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "![Split MNIST (Nature)](images/results_p3_smnist.png)\n",
    "\n",
    "\n",
    "\n",
    "![Split MNIST](images/results_p1_smnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brain-inspired modifications to GR\n",
    "\n",
    "### Motivation: Replay does not need to be perfect BUT also NOT LOW QUALITY\n",
    "  - __Simple approach__: Use recent progress in generative modelling with DNNs\n",
    "    - Drawbacks: Train those models is complex and expensive\n",
    "  - __Adopted approach__: Follow brain inspiration\n",
    "  \n",
    "### Techniques used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Take Aways\n",
    "\n",
    "üí° Ensure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reflections/Open Questions\n",
    "\n",
    "- I share with Terrence J. Sejnowski the following ‚ÄúMy belief in [artificial] neural networks was based on my intuition that if nature had solved this problems [vision, speech & language,] we should be able to learn from nature how to solve them, too.‚Äù\n",
    "\n",
    "- The paper does not compare their method with [Fearnet (Ronald Kemker and Christopher Kanan) in ICLR 2018](https://openreview.net/forum?id=SJ1Xmf-Rb), a generative model (that is memory efficient) that does not store previous examples, which apparently was getting SotA performance at incremental class learning on CIFAR-100\n",
    "\n",
    "- Fun Fact: None of the latest two big surveys about Continual Learning includes any reference to these authors:\n",
    "\n",
    "    - [A continual learning survey: Defying forgetting in classification tasks (2020)](https://arxiv.org/pdf/1909.08383.pdf)\n",
    "    - [Continual Lifelong Learning with Neural Networks: A Review (2019)](https://arxiv.org/pdf/1802.07569.pdf)\n",
    "\n",
    "\n",
    "- Nice set of papers appliying some of the recent advances in neuroscience/learning sciences\n",
    "    - In particular episodic memory and brain structures involved (hyppocampus and neocortex)\n",
    "    - Show how the current methods applying generative replay do not mimic exactly the real communication happening in the brain when learning\n",
    "    - Apparently [great source code](https://github.com/GMvandeVen/continual-learning) available\n",
    "\n",
    "\n",
    "- Can generative replay (or a similar technique) be applied to Transformer-based models?\n",
    "\n",
    "    - In particular to:\n",
    "        - Incremental tasks in text classification\n",
    "        - Hierarchical text classification tasks when adding new categories\n",
    "    - Would it be really necessary to have an extra generator? \n",
    "        - Can be based on the mere sampling of a small set of previous tasks examples only (e.g. applying zero-shot learning techniques)? \n",
    "        - Or maybe a can be expanded with a masked language model like ROBERTA to generate stuff automatically, in a similar way as some of the test cases generation described in [Beyond Accuracy: Behavioral Testing of NLP models with CheckList](https://arxiv.org/abs/2005.04118)\n",
    "\n",
    " \n",
    "- Is the controversy introduced in [1] when saying that generative replay _shifts_ the catastrophic forgetting problem to the training of the generative model_ really overcomed by this work? Or this paper shows that is not true and that a small amount of good enough replay generated by the model itself avoids most of the catastrophic forgetting occurring in the different scenarios?\n",
    "\n",
    "- I aggree, as it is also stated in [3], that \"In essence, in machine learning, in addition to adding depth to our networks, we may need to add intelligence to our synapses.\"\n",
    "\n",
    "- Observing and learn about how the brain works and translate the advances of neuroscience/learning science/psicology/psychiatry into the machine learning field has been proven very effective, specially in the last few years where computing power and data has grown almost exponentially. However, may obsesively trying mimic how the brain works, limit/shadow the potential of what additional artificial structures can add/complement to enhance the learning capabilities of current algorithms/techniques? As several theories proposed -See R. Kurtzweil for example-, maybe the changes we should pursue to advance the capacity of artificial \"brains\", should be similar to the structural changes caused by the evolution of neocortex [2] with regard to other species, and specially inside the primates.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[1] Jonathan Schwarz, Jelena Luketina, Wojciech M Czarnecki, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell. [Progress & compress: A scalable framework for continual learning (ICLM 2020)](https://arxiv.org/pdf/1805.06370.pdf)\n",
    "\n",
    "[2] Jon H. Kaas (Prog Brain Res. 2012 ; 195: 91‚Äì102. doi:10.1016/B978-0-444-53860-4.00005-20) [The evolution of neocortex in primates](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3787901/pdf/nihms516054.pdf)\n",
    "\n",
    "[3] Friedemann Zenke, Ben Poole, Surya Ganguli. [Continual Learning Through Synaptic Intelligence](https://arxiv.org/abs/1703.04200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PDF Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"Ven et al. - 2020 - Brain-inspired replay for continual learning with.pdf\", width=1500, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "IFrame(\"Generative replay with feedback connections as a general strategy for continual learning.pdf\", width=1500, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "IFrame(\"Three Scenarios for Continual Learning.pdf\", width=1500, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
