{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_slideshow_at': 'selected',\n",
       " 'leap_motion': {'naturalSwipe': True,\n",
       "  'pointerOpacity': 0.5,\n",
       "  'pointerColor': '#d80000'},\n",
       " 'header': '<h3>Francisco Perez-Sorrosal</h3>',\n",
       " 'footer': '<h3>Machine Learning/Deep Learning</h3>',\n",
       " 'scroll': True,\n",
       " 'enable_chalkboard': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "cm.update(\n",
    "    \"rise\",\n",
    "    {\n",
    "        \"theme\": None,\n",
    "        \"transition\": None,\n",
    "        \"start_slideshow_at\": \"selected\",\n",
    "        \"leap_motion\": {\n",
    "            \"naturalSwipe\"  : True,     # Invert swipe gestures\n",
    "            \"pointerOpacity\": 0.5,      # Set pointer opacity to 0.5\n",
    "            \"pointerColor\"  : \"#d80000\" # Red pointer\"nat.png\"\n",
    "        },\n",
    "        \"header\": \"<h3>Francisco Perez-Sorrosal</h3>\",\n",
    "        \"footer\": \"<h3>Machine Learning/Deep Learning</h3>\",\n",
    "        \"scroll\": True,\n",
    "        \"enable_chalkboard\": True\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: emoji in /Users/fperez/anaconda3/envs/transformers/lib/python3.7/site-packages (0.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presenting stuff is easy!!! üëç\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.emojize('Presenting stuff is easy!!! :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Emojis http://getemoji.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Replay with Feedback Connections as a General Strategy for Continual Learning\n",
    "\n",
    "## With Excerps from \"Three Scenarios for Continual Learning\"\n",
    "\n",
    "## Gido M. van de Ven & Andreas S. Tolias\n",
    "\n",
    "### [https://arxiv.org/pdf/1809.10635v2.pdf](https://arxiv.org/pdf/1809.10635v2.pdf)\n",
    "### [https://arxiv.org/pdf/1904.07734.pdf](https://arxiv.org/pdf/1904.07734.pdf)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Francisco Perez-Sorrosal | 14 Nov 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary (What do the authors sell)\n",
    "\n",
    "**[Extended version of \"Brain-inspired replay for continual learning with artiÔ¨Åcial neural networks\" Nature (2020)](https://www.nature.com/articles/s41467-020-17866-2.epdf?sharing_token=bkJqxr4qptypBkYehsw_FtRgN0jAjWel9jnR3ZoTv0NoUJpE84DVnSx_jyG1N8KQimOuCCtJtaDabIpjOWE47UccZTsgeeOekV8ng2BR-omuTPXahD4aCOiCIIfIO2IOB-qJOABLKf7BlAYsTBE8rCeZYZcKd0yuWJjlzAEc1G8%3D)**\n",
    "\n",
    "## Context:\n",
    "\n",
    "- Catastrophic Forgetting: Cites McCloskey and Ratcliff psychology-based papers from early 90's on the problems of the connectionist paradigm for avoiding \"memory loss\"\n",
    "\n",
    "    \"New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.\"\n",
    "\n",
    "    -- McCloskey et al.\n",
    "\n",
    "## Main contributions:\n",
    "\n",
    "üí° Make comparison of continual learning scenarios easy\n",
    "  - Identifies 3 distinct scenarios depending on if the task identity is provided at test time or not.\n",
    "\n",
    "üí° Compare recently proposed methond on continual learning\n",
    "\n",
    "üí° Propose a new efficient generative replay approach that behaves well in the 3 scenarios proposed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Continual Learning Scenarios\n",
    "\n",
    "üí° **KEY**: *WHETHER OR NOT* the model is required to identify the identity of the task it has to solve at test time\n",
    "\n",
    "  - e.g. In N. Masse et al.'s \"Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization\", which assumes task identity is always available, it is reported a great improvement over SotA.\n",
    "\n",
    "\n",
    "##  Scenarios:\n",
    " \n",
    " 1. Models are **always** informed about which task is solving\n",
    " \n",
    " \n",
    " 2. Models **do not know** the task identity at test time (domain-incremental learning, Domain-IL)\n",
    "   - However, the model do not need to infer the task, only solve it\n",
    " \n",
    " \n",
    " 3. Models need to both, **solve each task seen and infer which task** are currently evaluating (class-incremental learning, Class-IL)\n",
    " \n",
    " ![3Scenarios for CL](images/3scenarios.png)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Three Scenarios for Continual Learning (pdf)](https://arxiv.org/pdf/1904.07734.pdf)\n",
    "\n",
    "## Gido M. van de Ven & Andreas S. Tolias\n",
    "\n",
    "### Neurips 2019\n",
    "\n",
    "\n",
    "Extended description of the scenarios addressing the following:\n",
    "\n",
    "üí° The scenarios for Continual Learning Analisys\n",
    "\n",
    "üí° Strategies for Continual Learning\n",
    "\n",
    "üí° Experiments based on the previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Scenarios\n",
    "\n",
    "## Task-IL\n",
    "\n",
    "- The easiest continual learning scenario\n",
    "- Models are always informed about which task needs to be performed\n",
    "- It's possible to train models with task-specific components. \n",
    "- Typical network architecture in this scenario has a ‚Äúmulti-headed‚Äù output layer\n",
    "\n",
    "## Domain-IL\n",
    "\n",
    "- Task identity is not available at test time\n",
    "- BUT... models however only need to **solve the task**, not infer the current task\n",
    "- Task structure is always the same, **BUT** the input-distribution changes\n",
    "- Example: agents that have to survive in different envs without previous knowledge of the environment itself\n",
    "\n",
    "## Class-IL\n",
    "\n",
    "- Models have to solve each task seen AND infer the new current task\n",
    "- Name refers to the fact that the model has to learn to identify new classes of objects like infants do in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Single Headed vs Multi-Headed Methods\n",
    "\n",
    "Classical view of the continual learning:\n",
    "\n",
    "üí° A multi-headed layout requires task identity to be known (Task-IL)\n",
    "\n",
    "üí° A single-headed layout **DOES NOT** requires the task identity to be known (Domain-IL/Class-IL)\n",
    "\n",
    "This distinction is done **based on the architectural layout of a network‚Äôs output layer**. \n",
    "\n",
    "- **BUT** despite using a separate output layer for each task, it is the most common way to have specific task identity information, **it is not the only way**\n",
    "\n",
    "- For a single-headed layout might by\n",
    "itself not require task identity to be known, it is still possible for the model to use task identity in\n",
    "other way (See \"Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization\" by N. Masse et al.)\n",
    "\n",
    "## Major differences/advantages of the 3 scenarios proposal vs the Single/Multi Headed classical view...\n",
    "\n",
    "1. The scenarios proposed in the paper reflect more generally the conditions under which a model is evaluated.\n",
    "\n",
    "2. The scenarios extend upon the multi-headed vs single-headed split by recognizing that:\n",
    "    - when task identity is not provided, there is a further distinction depending on whether the network is explicitly required to infer task identity\n",
    "    - the two scenarios resulting from this additional split substantially differ in difficult\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Take Aways\n",
    "\n",
    "üí° Ensure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reflections/Open Questions\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PDF Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"1200\"\n",
       "            src=\"./Generative replay with feedback connections as a general strategy for continual learning.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fedb84c7a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./Generative replay with feedback connections as a general strategy for continual learning.pdf\", width=1500, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"1200\"\n",
       "            src=\"Three Scenarios for Continual Learning.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fedb84c7dd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"Three Scenarios for Continual Learning.pdf\", width=1500, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
