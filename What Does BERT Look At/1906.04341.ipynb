{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_slideshow_at': 'selected',\n",
       " 'leap_motion': {'naturalSwipe': True,\n",
       "  'pointerOpacity': 0.5,\n",
       "  'pointerColor': '#d80000'},\n",
       " 'header': '<h3>Francisco Perez-Sorrosal</h3>',\n",
       " 'footer': '<h3>Machine Learning/Deep Learning</h3>',\n",
       " 'scroll': True,\n",
       " 'enable_chalkboard': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from traitlets.config.manager import BaseJSONConfigManager\n",
    "from pathlib import Path\n",
    "path = Path.home() / \".jupyter\" / \"nbconfig\"\n",
    "cm = BaseJSONConfigManager(config_dir=str(path))\n",
    "cm.update(\n",
    "    \"rise\",\n",
    "    {\n",
    "        \"theme\": None,\n",
    "        \"transition\": None,\n",
    "        \"start_slideshow_at\": \"selected\",\n",
    "        \"leap_motion\": {\n",
    "            \"naturalSwipe\"  : True,     # Invert swipe gestures\n",
    "            \"pointerOpacity\": 0.5,      # Set pointer opacity to 0.5\n",
    "            \"pointerColor\"  : \"#d80000\" # Red pointer\"nat.png\"\n",
    "        },\n",
    "        \"header\": \"<h3>Francisco Perez-Sorrosal</h3>\",\n",
    "        \"footer\": \"<h3>Machine Learning/Deep Learning</h3>\",\n",
    "        \"scroll\": True,\n",
    "        \"enable_chalkboard\": True\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "print(emoji.emojize('Presenting stuff is easy!!! :thumbs_up:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Emojis http://getemoji.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What Does BERT Look At?\n",
    "### An Analysis of BERT‚Äôs Attention\n",
    "\n",
    "## Kevin Clark, Urvashi Khandelwal, Omer Levy and Christopher D. Manning\n",
    "\n",
    "# + Jesse Vig's Blog Post on Bert Deconstruction\n",
    "\n",
    "### [Clark et at. pdf](https://arxiv.org/pdf/1906.04341.pdf)\n",
    "\n",
    "### [Deconstructing BERT 1 (Dec 2018)](https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77)\n",
    "### [Deconstructing BERT 2 (Jan 2019)](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Francisco Perez-Sorrosal | 16 Mar 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary (What do the authors sell)\n",
    "\n",
    "üí° Language models achieve high accuracy in supervised task but not understood why.\n",
    "\n",
    "üí° Analyze the attention mechanisms of pre-trained models and apply them to BERT.\n",
    "\n",
    "üí° Claim that attention heads:\n",
    "\n",
    "* Attend to delimiter tokens\n",
    "* Positional offsets\n",
    "* Attend broadly to whole sentence\n",
    "* Heads in the same layer attend to similar behaviors\n",
    "* Certain heads attend to linguistic notions (e.g. syntax and correference)\n",
    "\n",
    "üí° Propose attention-based probing classifier (Not analyzed here)\n",
    "\n",
    "üí° Use it to demonstrate that substantial syntactic information is captured in BERT‚Äôs attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hypothesys\n",
    "\n",
    "## Pre-training makes the model learn about the structure of the language\n",
    "\n",
    "* What does it learn?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformers and BERT\n",
    "\n",
    "* Usual stuff on the transformers:\n",
    " - When producing the representation of the current token:\n",
    "   - Attention weights govern how ‚Äúimportant‚Äù every other token is for this one\n",
    "* Special Tokens:\n",
    " - Authors claim that they play a special role in attention mechanism\n",
    " - [CLS] Added at the begining of the text\n",
    " - [SEP]:\n",
    "   - Mark sentence boundaries\n",
    "   - Added at the end or...\n",
    "   - If input has multiple separate texts (e.g. question and context), [SEP] tokens are also used to separate them\n",
    "   - Additionally, BERT incorporates sentence-level embeddings (token_type_ids in HFT),added to the input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT Surface-Level Attention Heads Study (Clark et al.)\n",
    "\n",
    "* 128 tokens from Wikipedia, only two paragraphs\n",
    "* [CLS]\\<paragraph-1\\>[SEP]\\<paragraph-2\\>[SEP]\n",
    "\n",
    "## Relative Position\n",
    "\n",
    " - Most heads puts little attention to the current token\n",
    " - **Early layers**: Some heads specialize in next/prev token\n",
    "    - Prev: 2, 4, 7 and 8\n",
    "    - Next: 1, 2, 3 and 6\n",
    " \n",
    "## Separator Tokens\n",
    "\n",
    " - Early layers: Attend to CLS\n",
    " - Middle layers (5-10): Attend to SEP\n",
    " - Later layers: Attend to , and .    \n",
    "\n",
    " - More than half of the attention goes to the special tokens\n",
    "  - Specially the deliminator token [SEP]\n",
    "  - When current token is [SEP], heads attend even more at [SEP]\n",
    "    \n",
    "![SEP Attention](images/sep_attn.png)\n",
    " \n",
    "### Analysis\n",
    " - [CLS] and [SEP] are never masked out\n",
    " - In their context [SEP] occurs 1/64 times\n",
    " - . and , are the most common tokens (after \"the\")\n",
    "\n",
    "#### [SEP] is used to aggregate segment-level information\n",
    " - Then it can be further read by other layers\n",
    " - Not very likely bc:\n",
    "  - It is not observed that attention heads processing [SEP] broadly attend the whole segment\n",
    " - Instead, attention heads processing [SEP] attend to themselves and another [SEP]\n",
    "    \n",
    "#### Authors claim [SEP] is used by the model as a sort of no-op\n",
    " - Why? Non-nouns mostly attend to [SEP] (See figure below)\n",
    "![Head 8-10](images/head8-10.png)\n",
    " - How? Measuring how much changing the attention to a token will change BERT output\n",
    "  - Staring in layer 5, where attention to [SEP] is high, the gradients of this attention are small\n",
    "  - This means that [SEP] does not change fundamentally BERT's output\n",
    "![SEP attention gradient](images/sep_attn_grad.png)    \n",
    "\n",
    "## Broad vs Local Attention\n",
    "- How? Compute average entropy of every head's attention distribution\n",
    " - Lower layers:\n",
    "   - Attention heads have broad attention\n",
    "   - 10% of the attention mass on a single word\n",
    "   - Output: A BoW representation of the sentence \n",
    " - Last layer:\n",
    "   - Broad attention/High entropy from [CLS] (3.89)\n",
    "   - [CLS] attends broadly to aggregate the whole input in the last layer\n",
    "![Entropy Attention Distribution](images/entropy_attn_dist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6 BERT Patterns (J. Vig)\n",
    "\n",
    "Author disclaimer:\n",
    "\n",
    "- Visualizations used as kind of Rorschach tests\n",
    "  - That is, may lead to subjective interpretations\n",
    "- Do not talk about the structure of the language\n",
    "  - synonymy, coreference, etc.\n",
    "\n",
    "## Pattern 1/2: Attention to next word (1) / previous word (2)\n",
    "\n",
    "- Same conclusion is extracted by Clarke et al. in the Relative Position section\n",
    "- Loosely related to a sequential RNN (next=backward/prev=forward)\n",
    "- Appears over multiple layers of the model (although he doesn't specifies where)\n",
    "- [SEP] apparently disrupts the next-word attention pattern\n",
    "  - Attention from [SEP] is directed to [CLS]\n",
    "  \n",
    "![Next Token Attention](images/next_token_attn.png) \n",
    "\n",
    "\n",
    "## Pattern 3/4: Attention to identical/related words (patt. 3) in other sentence (patt. 4)\n",
    "\n",
    "- This attention also seems to cross segments (See figures below)\n",
    "- This can also be appreciated in Clark et al paper in Figure 5 in the paper for Head 7-6, 9-6 and 5-4\n",
    "- Doesn't seem to happen for the special tokens [CLS]/[SEP] (See below) although in Clark's paper figures mentioned above appears lightly\n",
    "\n",
    "#### Pattern 3\n",
    "![Token Self Attention](images/token_self_attn.png) \n",
    "\n",
    "#### Pattern 4\n",
    "\n",
    "![Cross Segment Attention](images/cross_segments.png) \n",
    "\n",
    "## Pattern 5: Attention to other words predictive of word\n",
    "\n",
    "- Related to Word Piece tokenization used by BERT\n",
    "- ‚Äústraw‚Äù is directed to ‚Äú##berries‚Äù, and most of the attention from ‚Äú##berries‚Äù is focused on ‚Äústraw‚Äù\n",
    "- Seems to reinforce the idea that those to tokens are very tied together\n",
    "\n",
    "## Pattern 6: Attention to delimiter tokens\n",
    "\n",
    "- Same conclusion is extracted by Clarke et al. in the Separator Tokens section (Chicken or Egg)\n",
    "- Does not enter in detail about [CLS]/[SEP] differences\n",
    "- Cites Clark and mentions [SEP] is used as a‚Äúno-op‚Äù: an attention head focuses on the [SEP] tokens when it can‚Äôt find anything meaningful in the input sentence to focus on\n",
    "\n",
    "![SEP Attention](images/sep_attn_vig.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT Patterns from 2nd Blog Post (J. Vig)\n",
    "\n",
    "\n",
    "## Delimiter-focused attention patterns (Pattern 6)\n",
    "\n",
    "- How BERT fixates on the [SEP] tokens?\n",
    "\n",
    "![SEP Attention](images/sep_attn_vig2.png)\n",
    "\n",
    "- key vectors for the 2 [SEP] have a distinctive signature\n",
    "  - small number of active neurons with strongly positive (blue) or negative (orange) values\n",
    "  - a larger number of neurons with values close to zero (light blue/orange or white)\n",
    "- only a few neurons are required because the pattern is relatively simple\n",
    "  - also little variation in the words that receive attention\n",
    "\n",
    "![SEP Attention Neurons](images/sep_attn_vig2_neuron.png)\n",
    "\n",
    "- the elementwise product produces high values\n",
    "  - they match the [SEP] key vector\n",
    "- can we talk about [SEP]-matching neurons??? and query vectors are assigned values that match the [SEP] key vectors at these positions\n",
    "  \n",
    "![Elemwise Product QxK](images/elemwise_prod.png)\n",
    "\n",
    "## Bag of Words attention pattern\n",
    "\n",
    "- Not discussed in Part 1\n",
    "- Meaning: Attention divided fairly evenly across all words in the same sentence\n",
    "  - What in Clark et al. is called Broad vs Local Attention\n",
    "  - BoW embedding by with an unweighted average of the word embeddings in the same sentence\n",
    "\n",
    "![BoW Neuron](images/bow_neuron.png)\n",
    "\n",
    "- Elementwise multiplication\n",
    "  - q, k in the same sentence: the mult. shows high values (q, k have same signs)\n",
    "  - q, k in the different sentences: the mult. shows negative values (q, k have opposite signs)\n",
    "  \n",
    "![BoW Neuron](images/bow_neuron.png)\n",
    "\n",
    "- only a few neurons are required because the pattern is relatively simple\n",
    "  - also little variation in the words that receive attention\n",
    "\n",
    "## Next-word attention patterns (Pattern 1)\n",
    "\n",
    "- Focusing in next/prev word makes sense\n",
    "  - Adjacent words are relevant for understanding the current's word meaning (at least in english)\n",
    "  - n-gram LM are based on this\n",
    "  \n",
    "- The pattern requires high number of neurons to figure out the attention score\n",
    "  - Why? to keep track of which of the 128 (512) words receives attention from a given position\n",
    "\n",
    "![Next Token Attention Neuron](images/next_token_attn_neuron.png) \n",
    "\n",
    "- The elementwise product of q2 and the key vector for k3 (the next word) is strongly positive across most neurons\n",
    "  - See the strong blue patterns in the figure below\n",
    "- For non-next tokens, the QxK product has some combination of positive and negative values\n",
    "  \n",
    "![Next Token Attention QxK](images/next_token_attn_elementwise.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Take Aways\n",
    "\n",
    "üí° Current analysis of models focus on probing vector representations of model outputs, BUT...\n",
    "\n",
    " - Study of attention maps should be done as attention maps hold Linguistic knowledge\n",
    " - These tools should be part of researchers in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reflections/Open Questions\n",
    "\n",
    "- Pretty interesting paper/blog entries related to interpretability\n",
    "\n",
    "- How unused special tokens affect input?\n",
    "  - That is, can they learn structure or embed knowledge depending on the target task?\n",
    "\n",
    "- Related:\n",
    " \n",
    " - [Jesse Vig](https://jessevig.com/)\n",
    " - [BERT Viz (Jesse Vig)](https://github.com/jessevig/bertviz)\n",
    " - [How does BERT‚Äôs attention change when you fine-tune? An analysis methodology and a case study in negation scope](https://www.aclweb.org/anthology/2020.acl-main.429.pdf) ACL 2020\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PDF Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"1200\"\n",
       "            src=\"./2005.04118.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd4085fb5d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"./1906.04341.pdf\", width=1500, height=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "livereveal": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
